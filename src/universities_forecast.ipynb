{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e6803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS POR UNIVERSIDADE (ARIMA(3,0,1) + EXÃ“GENAS + FOURIER + MASKS) ===\n",
      "                                         Universidade Estado  Latitude  \\\n",
      "0   Universidade Federal do Acre (UFAC) â€“ Campus R...     AC  -9.95784   \n",
      "1   Universidade Federal de Alagoas (UFAL) â€“ Campu...     AL  -9.55232   \n",
      "2   Universidade Federal do Amazonas (UFAM) â€“ Camp...     AM  -3.09303   \n",
      "3   Universidade Federal do AmapÃ¡ (UNIFAP) â€“ Campu...     AP  -0.00624   \n",
      "4   Universidade Federal da Bahia (UFBA) â€“ Campus ...     BA -13.00178   \n",
      "5   Universidade Federal do CearÃ¡ (UFC) â€“ Campus d...     CE  -3.74455   \n",
      "6   Universidade Federal do EspÃ­rito Santo (UFES) ...     ES -20.27706   \n",
      "7   Universidade Federal de GoiÃ¡s (UFG) â€“ Campus S...     GO -16.60387   \n",
      "8   Universidade Federal do MaranhÃ£o (UFMA) â€“ Cida...     MA  -2.55932   \n",
      "9   Universidade Federal de Minas Gerais (UFMG) â€“ ...     MG -19.87069   \n",
      "10  Universidade Federal de Mato Grosso do Sul (UF...     MS -20.50170   \n",
      "11  Universidade Federal de Mato Grosso (UFMT) â€“ C...     MT -15.60167   \n",
      "12  Universidade Federal do ParÃ¡ (UFPA) â€“ Campus G...     PA  -1.47460   \n",
      "13  Universidade Federal da ParaÃ­ba (UFPB) â€“ Campu...     PB  -7.14161   \n",
      "14  Universidade Federal de Pernambuco (UFPE) â€“ Ci...     PE  -8.05066   \n",
      "15  Universidade Federal do PiauÃ­ (UFPI) â€“ Campus ...     PI  -5.05967   \n",
      "16  Universidade Federal do ParanÃ¡ (UFPR) â€“ Centro...     PR -25.45042   \n",
      "17  Universidade Federal do Rio de Janeiro (UFRJ) ...     RJ -22.86180   \n",
      "18  Universidade Federal do Rio Grande do Norte (U...     RN  -5.83810   \n",
      "19  Universidade Federal de RondÃ´nia (UNIR) â€“ Camp...     RO  -8.76340   \n",
      "20  Universidade Federal de Roraima (UFRR) â€“ Campu...     RR   2.82379   \n",
      "21  Universidade Federal do Rio Grande do Sul (UFR...     RS -30.07383   \n",
      "22  Universidade Federal de Santa Catarina (UFSC) ...     SC -27.60191   \n",
      "23  Universidade Federal de Sergipe (UFS) â€“ Campus...     SE -10.92386   \n",
      "24  Universidade Federal do ABC (UFABC) â€“ Campus S...     SP -23.65013   \n",
      "25  Universidade Federal do Tocantins (UFT) â€“ Camp...     TO -10.18271   \n",
      "\n",
      "    Longitude                  PerÃ­odo  Obs Totais  Treino  Teste  \\\n",
      "0   -67.86869  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "1   -35.77772  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "2   -59.96418  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "3   -51.08353  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "4   -38.50934  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "5   -38.57571  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "6   -40.30351  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "7   -49.26239  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "8   -44.30733  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "9   -43.96715  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "10  -54.61506  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "11  -56.06394  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "12  -48.45298  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "13  -34.84535  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "14  -34.94953  2019-01-01 â†’ 2023-12-31        1826    1460    366   \n",
      "15  -42.80142  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "16  -49.23409  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "17  -43.22470  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "18  -35.19999  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "19  -63.90276  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "20  -60.67592  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "21  -51.12069  2019-01-01 â†’ 2021-12-31        1096     876    220   \n",
      "22  -48.51904  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "23  -37.10824  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "24  -46.53269  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "25  -48.33335  2019-01-01 â†’ 2024-12-31        2192    1753    439   \n",
      "\n",
      "    RMSE (debias)    MSE  sMAPE (%)  \n",
      "0           1.327  1.762      3.553  \n",
      "1           0.759  0.576      2.350  \n",
      "2           0.715  0.511      2.127  \n",
      "3           0.670  0.449      1.744  \n",
      "4           0.760  0.578      2.334  \n",
      "5           1.678  2.816      4.781  \n",
      "6           1.488  2.213      4.923  \n",
      "7           1.337  1.788      4.479  \n",
      "8           0.588  0.346      1.750  \n",
      "9           1.565  2.449      5.990  \n",
      "10          2.003  4.011      6.851  \n",
      "11          1.602  2.568      3.949  \n",
      "12          0.561  0.314      1.591  \n",
      "13          0.739  0.546      2.235  \n",
      "14          0.383  0.146      1.313  \n",
      "15          0.643  0.414      1.679  \n",
      "16          2.621  6.868     12.008  \n",
      "17          1.656  2.744      5.540  \n",
      "18          1.031  1.064      2.737  \n",
      "19          1.091  1.190      3.008  \n",
      "20          1.639  2.685      5.093  \n",
      "21          2.423  5.870     11.690  \n",
      "22          2.411  5.812      8.846  \n",
      "23          0.793  0.629      2.458  \n",
      "24          2.127  4.524      8.314  \n",
      "25          2.322  5.391      7.029  \n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import warnings\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "\n",
    "warnings.simplefilter(\"ignore\", ConvergenceWarning)\n",
    "\n",
    "# =============================\n",
    "# ConfiguraÃ§Ãµes\n",
    "# =============================\n",
    "STATIONS_CSV = \"../data/all_stations.csv\"\n",
    "UNI_CSV = \"./universidades_federais_coords_26_estados.csv\"\n",
    "CLEANED_BASE = \"../data/cleaned_data\"\n",
    "YEARS = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "RADIUS_KM = 35.0\n",
    "\n",
    "FORECAST_PARAMETER = \"TEMPERATURA DO AR - BULBO SECO, HORARIA (Â°C)\"\n",
    "EXOG_VARS = [\n",
    "    \"RADIACAO GLOBAL (KJ/mÂ²)\",\n",
    "    \"PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)\",\n",
    "    \"UMIDADE RELATIVA DO AR, HORARIA (%)\",\n",
    "]\n",
    "\n",
    "RESAMPLE_RULE = \"D\"     # mÃ©dia diÃ¡ria\n",
    "SPLIT_TRAIN = 0.80      # 80/20 treino/teste\n",
    "ARIMA_ORDER = (3, 0, 1) # ARIMA(3,0,1)\n",
    "FOURIER_PERIOD = 365    # dias\n",
    "FOURIER_K = 4           # nÂº de harmÃ´nicos (gera 2*K colunas)\n",
    "\n",
    "# =============================\n",
    "# Utilidades bÃ¡sicas\n",
    "# =============================\n",
    "def calculate_distance_from_point_to_station(row, given_point_coord):\n",
    "    station_coord = (row[\"LATITUDE:\"], row[\"LONGITUDE:\"])\n",
    "    return geodesic(station_coord, given_point_coord).kilometers\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true, y_pred = pd.Series(y_true), pd.Series(y_pred)\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / (np.abs(y_pred) + np.abs(y_true)))\n",
    "\n",
    "def create_fourier_terms(t, period, num_terms):\n",
    "    terms = []\n",
    "    for i in range(1, num_terms + 1):\n",
    "        terms.append(np.sin(2 * np.pi * i * t / period))\n",
    "        terms.append(np.cos(2 * np.pi * i * t / period))\n",
    "    return np.column_stack(terms)\n",
    "\n",
    "# =============================\n",
    "# Leitura de estaÃ§Ãµes e dados\n",
    "# =============================\n",
    "def load_all_stations() -> pd.DataFrame:\n",
    "    df_all_stations = pd.read_csv(STATIONS_CSV, decimal=\",\", sep=\";\")\n",
    "    df_all_stations.columns = [c.strip() for c in df_all_stations.columns]\n",
    "    return df_all_stations\n",
    "\n",
    "def load_weather_for_station_filename(filename_2019: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Usa o nome-base de 2019 e monta os caminhos 2019â€“2024.\n",
    "    Concatena o que existir, e corrige 'RADIACAO GLOBAL (Kj/mÂ²)' -> 'RADIACAO GLOBAL (KJ/mÂ²)'.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    for year in YEARS:\n",
    "        year_dir = f\"{year}_cleaned\"\n",
    "        target = filename_2019.replace(\"2019\", str(year))\n",
    "        path = os.path.join(CLEANED_BASE, year_dir, target)\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                df_weather_data = pd.read_csv(path, decimal=\".\", sep=\";\")\n",
    "                # ðŸ”§ correÃ§Ã£o de nomenclatura (Kj â†’ KJ)\n",
    "                if 'RADIACAO GLOBAL (Kj/mÂ²)' in df_weather_data.columns:\n",
    "                    df_weather_data.rename(\n",
    "                        columns={'RADIACAO GLOBAL (Kj/mÂ²)': 'RADIACAO GLOBAL (KJ/mÂ²)'},\n",
    "                        inplace=True\n",
    "                    )\n",
    "                dfs.append(df_weather_data)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Falha ao ler {path}: {e}\")\n",
    "    if not dfs:\n",
    "        return None\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def build_daily_panel_from_stations(df_nearest_stations: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Retorna um DataFrame diÃ¡rio (index=Data) com mÃ©dia das variÃ¡veis numÃ©ricas\n",
    "    das estaÃ§Ãµes do raio. MantÃ©m target + exÃ³genas, faz ffill().\n",
    "    \"\"\"\n",
    "    collected = []\n",
    "    for filename in df_nearest_stations[\"Arquivo\"]:\n",
    "        dfw = load_weather_for_station_filename(filename)\n",
    "        if dfw is not None:\n",
    "            collected.append(dfw)\n",
    "    if not collected:\n",
    "        return None\n",
    "\n",
    "    df = pd.concat(collected, ignore_index=True)\n",
    "    if \"Hora UTC\" in df.columns:\n",
    "        df = df.drop(columns=[\"Hora UTC\"])\n",
    "    df[\"Data\"] = pd.to_datetime(df[\"Data\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Data\"]).sort_values(\"Data\").set_index(\"Data\")\n",
    "\n",
    "    daily = df.resample(RESAMPLE_RULE).mean(numeric_only=True)\n",
    "\n",
    "    # garantir colunas requeridas\n",
    "    needed = [FORECAST_PARAMETER] + EXOG_VARS\n",
    "    missing = [c for c in needed if c not in daily.columns]\n",
    "    if missing:\n",
    "        raise KeyError(f\"Colunas faltando apÃ³s resample: {missing}\\nDisponÃ­veis: {list(daily.columns)[:12]} ...\")\n",
    "\n",
    "    daily = daily.ffill()\n",
    "    return daily\n",
    "\n",
    "def series_for_coord(coord: Tuple[float, float], df_all_stations: pd.DataFrame) -> Optional[pd.DataFrame]:\n",
    "    df = df_all_stations.copy()\n",
    "    df[\"Distancia\"] = df.apply(lambda r: calculate_distance_from_point_to_station(r, coord), axis=1)\n",
    "    df_nearest = df[df[\"Distancia\"] < RADIUS_KM]\n",
    "    if df_nearest.empty:\n",
    "        df_nearest = df.sort_values(\"Distancia\").head(1)  # fallback: estaÃ§Ã£o mais prÃ³xima\n",
    "    return build_daily_panel_from_stations(df_nearest)\n",
    "\n",
    "# =============================\n",
    "# ExÃ³genas com mÃ¡scaras (sem vazamento)\n",
    "# =============================\n",
    "def _profiles_from_train(df_training: pd.DataFrame, exog_vars):\n",
    "    prof_mmdd = (\n",
    "        df_training.assign(__mm__=df_training.index.month, __dd__=df_training.index.day)\n",
    "                   .groupby([\"__mm__\", \"__dd__\"])[exog_vars]\n",
    "                   .median()\n",
    "    )\n",
    "    prof_doy = (\n",
    "        df_training.assign(__doy__=df_training.index.dayofyear)\n",
    "                   .groupby(\"__doy__\")[exog_vars]\n",
    "                   .median()\n",
    "    )\n",
    "    return prof_mmdd, prof_doy\n",
    "\n",
    "def _impute_with_profiles(s: pd.Series, mmdd_index, doy_index, prof_mmdd, prof_doy, train_col_median):\n",
    "    need = s.isna()\n",
    "    if need.any():\n",
    "        s.loc[need] = prof_mmdd[s.name].reindex(mmdd_index[need]).values\n",
    "    need = s.isna()\n",
    "    if need.any():\n",
    "        s.loc[need] = prof_doy[s.name].reindex(doy_index[need]).values\n",
    "    need = s.isna()\n",
    "    if need.any():\n",
    "        s.loc[need] = train_col_median\n",
    "    return s\n",
    "\n",
    "def prepare_exog_with_masks(df_training: pd.DataFrame,\n",
    "                            df_test: pd.DataFrame,\n",
    "                            exog_vars,\n",
    "                            fourier_period: int = FOURIER_PERIOD,\n",
    "                            fourier_k: int = FOURIER_K):\n",
    "    \"\"\"\n",
    "    Retorna X_train, X_test, feature_names com:\n",
    "      [exÃ³genas imputadas | mÃ¡scaras *_MISSING | Fourier]\n",
    "    MÃ¡scaras: 1 quando o valor ORIGINAL era NaN, 0 caso contrÃ¡rio.\n",
    "    ImputaÃ§Ã£o do TESTE usa apenas estatÃ­sticas do TREINO (sem vazamento).\n",
    "    \"\"\"\n",
    "    # mÃ¡scaras originais\n",
    "    train_masks = {f\"{col}_MISSING\": df_training[col].isna().astype(int) for col in exog_vars}\n",
    "    test_masks  = {f\"{col}_MISSING\": df_test[col].isna().astype(int)      for col in exog_vars}\n",
    "\n",
    "    prof_mmdd, prof_doy = _profiles_from_train(df_training, exog_vars)\n",
    "\n",
    "    # Ã­ndices auxiliares\n",
    "    mmdd_tr = pd.MultiIndex.from_arrays([df_training.index.month, df_training.index.day], names=[\"__mm__\", \"__dd__\"])\n",
    "    mmdd_te = pd.MultiIndex.from_arrays([df_test.index.month,     df_test.index.day    ], names=[\"__mm__\", \"__dd__\"])\n",
    "    doy_tr  = ((df_training.index.dayofyear - 1) % 365) + 1\n",
    "    doy_te  = ((df_test.index.dayofyear     - 1) % 365) + 1\n",
    "\n",
    "    tr_imp = df_training[exog_vars].copy()\n",
    "    te_imp = df_test[exog_vars].copy()\n",
    "\n",
    "    # imputaÃ§Ã£o treino\n",
    "    for col in exog_vars:\n",
    "        tr_imp[col] = _impute_with_profiles(\n",
    "            tr_imp[col], mmdd_tr, doy_tr, prof_mmdd, prof_doy,\n",
    "            train_col_median=df_training[col].median(skipna=True)\n",
    "        )\n",
    "    # imputaÃ§Ã£o teste (sem vazamento)\n",
    "    for col in exog_vars:\n",
    "        te_imp[col] = _impute_with_profiles(\n",
    "            te_imp[col], mmdd_te, doy_te, prof_mmdd, prof_doy,\n",
    "            train_col_median=df_training[col].median(skipna=True)\n",
    "        )\n",
    "\n",
    "    # Fourier\n",
    "    n_tr, n_te = len(df_training), len(df_test)\n",
    "    t_tr = np.arange(n_tr)\n",
    "    t_te = np.arange(n_tr, n_tr + n_te)\n",
    "    F_tr = create_fourier_terms(t_tr, fourier_period, fourier_k)\n",
    "    F_te = create_fourier_terms(t_te, fourier_period, fourier_k)\n",
    "    fourier_cols = [f\"F_{k}_{fn}\" for k in range(1, fourier_k + 1) for fn in (\"sin\", \"cos\")]\n",
    "\n",
    "    # monta X\n",
    "    X_train = np.hstack([\n",
    "        tr_imp.to_numpy(),\n",
    "        np.column_stack([train_masks[m].to_numpy() for m in train_masks]),\n",
    "        F_tr\n",
    "    ])\n",
    "    X_test  = np.hstack([\n",
    "        te_imp.to_numpy(),\n",
    "        np.column_stack([test_masks[m].to_numpy() for m in test_masks]),\n",
    "        F_te\n",
    "    ])\n",
    "\n",
    "    feature_names = list(exog_vars) + list(train_masks.keys()) + fourier_cols\n",
    "    return X_train, X_test, feature_names\n",
    "\n",
    "# =============================\n",
    "# ARIMA(3,0,1) com exÃ³genas + Fourier + calibraÃ§Ã£o\n",
    "# =============================\n",
    "def debias_with_calibration(model_fit, df_training, forecast_parameter, X_train_final, forecast_vals, calib_days=60):\n",
    "    start = max(0, len(df_training) - calib_days)\n",
    "    pred_cal = model_fit.get_prediction(\n",
    "        start=df_training.index[start],\n",
    "        end=df_training.index[-1],\n",
    "        exog=X_train_final[start:]\n",
    "    ).predicted_mean\n",
    "    y_cal = df_training[forecast_parameter].iloc[start:]\n",
    "    ME = (y_cal - pred_cal).mean()\n",
    "    forecast_bias_fixed = forecast_vals + ME\n",
    "    X = sm.add_constant(pred_cal.values)\n",
    "    a, b = sm.OLS(y_cal.values, X).fit().params\n",
    "    forecast_linear_cal = a + b * forecast_vals\n",
    "    return {\"ME\": ME, \"forecast_bias_fixed\": forecast_bias_fixed, \"a\": a, \"b\": b, \"forecast_linear_cal\": forecast_linear_cal}\n",
    "\n",
    "def arima_forecast_with_fourier_terms_exog(df_training: pd.DataFrame,\n",
    "                                           df_test: pd.DataFrame,\n",
    "                                           forecast_parameter: str,\n",
    "                                           trend: str = \"ct\",\n",
    "                                           calib_days: int = 60) -> pd.Series:\n",
    "    X_train, X_test, _ = prepare_exog_with_masks(df_training, df_test, EXOG_VARS, FOURIER_PERIOD, FOURIER_K)\n",
    "\n",
    "    model = ARIMA(df_training[forecast_parameter], exog=X_train, order=ARIMA_ORDER, trend=trend)\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    forecast_vals = model_fit.forecast(steps=len(df_test), exog=X_test)\n",
    "    cal = debias_with_calibration(model_fit, df_training, forecast_parameter, X_train, forecast_vals, calib_days=calib_days)\n",
    "\n",
    "    forecast_corrected = pd.Series(cal[\"forecast_bias_fixed\"], index=df_test.index, name=\"forecast\")\n",
    "    return forecast_corrected\n",
    "\n",
    "# =============================\n",
    "# Pipeline principal\n",
    "# =============================\n",
    "def run_for_coords(coords: List[Tuple[float, float]]) -> Dict[Tuple[float, float], Dict]:\n",
    "    df_all = load_all_stations()\n",
    "    results: Dict[Tuple[float, float], Dict] = {}\n",
    "\n",
    "    for coord in coords:\n",
    "        daily = series_for_coord(coord, df_all)\n",
    "        if daily is None:\n",
    "            results[coord] = {\"ok\": False, \"reason\": \"Sem dados para essa coordenada.\"}\n",
    "            continue\n",
    "\n",
    "        split_idx = int(len(daily) * SPLIT_TRAIN)\n",
    "        df_training = daily.iloc[:split_idx].copy()\n",
    "        df_test     = daily.iloc[split_idx:].copy()\n",
    "\n",
    "        # sanity check\n",
    "        needed = [FORECAST_PARAMETER] + EXOG_VARS\n",
    "        if any(col not in df_training.columns for col in needed) or any(col not in df_test.columns for col in needed):\n",
    "            results[coord] = {\"ok\": False, \"reason\": \"Colunas necessÃ¡rias ausentes (target/exÃ³genas).\"}\n",
    "            continue\n",
    "\n",
    "        forecast = arima_forecast_with_fourier_terms_exog(df_training, df_test, FORECAST_PARAMETER)\n",
    "\n",
    "        # mÃ©tricas (RMSE com debias; MSE; sMAPE)\n",
    "        mse = mean_squared_error(df_test[FORECAST_PARAMETER], forecast)\n",
    "        rmse = mse ** 0.5\n",
    "        smape_val = smape(df_test[FORECAST_PARAMETER], forecast)\n",
    "\n",
    "        results[coord] = {\n",
    "            \"ok\": True,\n",
    "            \"periodo\": f\"{daily.index.min().date()} â†’ {daily.index.max().date()}\",\n",
    "            \"n_total\": len(daily),\n",
    "            \"n_train\": len(df_training),\n",
    "            \"n_test\": len(df_test),\n",
    "            \"RMSE\": float(rmse),           # jÃ¡ com debias\n",
    "            \"MSE\": float(mse),\n",
    "            \"sMAPE\": float(smape_val),\n",
    "            \"forecast\": forecast,          # sÃ©rie prevista (apenas janela de teste)\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "# =============================\n",
    "# Rodar para TODAS as universidades e imprimir tabela\n",
    "# =============================\n",
    "# LÃª CSV das universidades\n",
    "try:\n",
    "    df_uni = pd.read_csv(UNI_CSV)  # tenta separador padrÃ£o\n",
    "except Exception:\n",
    "    df_uni = pd.read_csv(UNI_CSV, sep=\";\", decimal=\",\")  # fallback\n",
    "\n",
    "df_uni.columns = [c.strip() for c in df_uni.columns]\n",
    "assert {\"Universidade\", \"Estado\", \"Latitude\", \"Longitude\"}.issubset(df_uni.columns), \\\n",
    "    f\"CSV de universidades nÃ£o tem as colunas esperadas. Tenho: {df_uni.columns.tolist()}\"\n",
    "\n",
    "# Monta coords na mesma ordem do CSV\n",
    "coords = [(float(lat), float(lon)) for lat, lon in zip(df_uni[\"Latitude\"], df_uni[\"Longitude\"])]\n",
    "\n",
    "# Executa\n",
    "results = run_for_coords(coords)\n",
    "\n",
    "# Tabela final\n",
    "rows = []\n",
    "for i, coord in enumerate(coords):\n",
    "    uni = df_uni.iloc[i][\"Universidade\"]\n",
    "    uf  = df_uni.iloc[i][\"Estado\"]\n",
    "    r   = results.get(coord, {})\n",
    "    if r.get(\"ok\"):\n",
    "        rows.append({\n",
    "            \"Universidade\": uni,\n",
    "            \"Estado\": uf,\n",
    "            \"Latitude\": round(coord[0], 6),\n",
    "            \"Longitude\": round(coord[1], 6),\n",
    "            \"PerÃ­odo\": r[\"periodo\"],\n",
    "            \"Obs Totais\": r[\"n_total\"],\n",
    "            \"Treino\": r[\"n_train\"],\n",
    "            \"Teste\": r[\"n_test\"],\n",
    "            \"RMSE (debias)\": round(r[\"RMSE\"], 3),\n",
    "            \"MSE\": round(r[\"MSE\"], 3),\n",
    "            \"sMAPE (%)\": round(r[\"sMAPE\"], 3),\n",
    "        })\n",
    "    else:\n",
    "        rows.append({\n",
    "            \"Universidade\": uni,\n",
    "            \"Estado\": uf,\n",
    "            \"Latitude\": round(coord[0], 6),\n",
    "            \"Longitude\": round(coord[1], 6),\n",
    "            \"Status\": \"Falhou\",\n",
    "            \"Motivo\": r.get(\"reason\", \"Sem dados apÃ³s filtro/transformaÃ§Ãµes\"),\n",
    "        })\n",
    "\n",
    "df_resultados = pd.DataFrame(rows)\n",
    "sort_cols = [c for c in [\"Status\", \"Estado\", \"Universidade\"] if c in df_resultados.columns]\n",
    "df_resultados = df_resultados.sort_values(by=sort_cols).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== RESULTADOS POR UNIVERSIDADE (ARIMA(3,0,1) + EXÃ“GENAS + FOURIER + MASKS) ===\")\n",
    "print(df_resultados)\n",
    "\n",
    "# opcional: salvar\n",
    "# df_resultados.to_csv(\"resultados_arima_universidades.csv\", index=False, sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fc1032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# TABELA COMPACTA PARA OVERLEAF (resize + colunas reduzidas)\n",
    "# =======================================================\n",
    "def print_latex_table_compact(df: pd.DataFrame,\n",
    "                              caption: str = \"Resultados por universidade (compacto)\",\n",
    "                              label: str = \"tab:resultados_compacto\",\n",
    "                              float_format: str = \"%.3f\",\n",
    "                              longtable: bool = False):\n",
    "    \"\"\"\n",
    "    Imprime no console uma tabela LaTeX compacta com:\n",
    "      Sigla | Campus | Estado | RMSE (debias) | sMAPE (%)\n",
    "    A tabela Ã© envolvida por \\resizebox{\\textwidth}{!}{...} para caber na pÃ¡gina.\n",
    "    NÃ£o altera df_resultados original e nÃ£o salva arquivos.\n",
    "    \"\"\"\n",
    "\n",
    "    import re\n",
    "    df2 = df.copy()\n",
    "\n",
    "    # ---------- extratores de Sigla e Campus a partir da coluna \"Universidade\" ----------\n",
    "    def _extrair_sigla(nome_uni: str) -> str:\n",
    "        # tenta pegar uma sigla jÃ¡ em maiÃºsculas (ex: UFMG, UFPR, IFRN...)\n",
    "        match = re.findall(r'\\b[A-Z]{2,}\\b', nome_uni or \"\")\n",
    "        if match:\n",
    "            return match[0]\n",
    "        # fallback: iniciais de palavras significativas\n",
    "        palavras = [p for p in re.split(r\"\\s+\", nome_uni or \"\") if p and p[0].isalpha()]\n",
    "        iniciais = \"\".join([p[0].upper() for p in palavras if len(p) > 2])\n",
    "        return iniciais[:6] or \"â€”\"\n",
    "\n",
    "    def _extrair_campus(nome_uni: str) -> str:\n",
    "        if not nome_uni:\n",
    "            return \"Sede\"\n",
    "        # padrÃµes comuns: \" - Campus X\", \" â€“ Campus X\", \"... (Campus X)\"\n",
    "        if re.search(r'Campus', nome_uni, flags=re.IGNORECASE):\n",
    "            # pega tudo apÃ³s a palavra Campus\n",
    "            pos = re.split(r'(?i)Campus', nome_uni, maxsplit=1)[-1]\n",
    "            pos = re.sub(r'^[\\s:\\-â€“]+', '', pos).strip()\n",
    "            # remove parÃªnteses finais, se vier \"Campus X)\"; mantÃ©m sÃ³ o nome\n",
    "            pos = re.sub(r'^\\(?\\s*(.*?)\\s*\\)?$', r'\\1', pos)\n",
    "            return pos if pos else \"Sede\"\n",
    "        # se nÃ£o houver \"Campus\", assume sede\n",
    "        return \"Sede\"\n",
    "\n",
    "    if \"Universidade\" in df2.columns:\n",
    "        df2[\"Sigla\"] = df2[\"Universidade\"].astype(str).apply(_extrair_sigla)\n",
    "        df2[\"Campus\"] = df2[\"Universidade\"].astype(str).apply(_extrair_campus)\n",
    "    else:\n",
    "        # se nÃ£o existir a coluna (caso raro), ainda assim cria vazias\n",
    "        df2[\"Sigla\"] = \"\"\n",
    "        df2[\"Campus\"] = \"Sede\"\n",
    "\n",
    "    # ---------- seleÃ§Ã£o de colunas compactas ----------\n",
    "    cols_final = [\"Sigla\", \"Campus\", \"Estado\", \"RMSE (debias)\", \"sMAPE (%)\"]\n",
    "    cols_final = [c for c in cols_final if c in df2.columns]\n",
    "    df2 = df2[cols_final].copy()\n",
    "\n",
    "    # renomeia \"sMAPE (%)\" -> \"sMAPE (\\%)\" para LaTeX\n",
    "    df2.rename(columns={c: c.replace(\"%\", r\"\\%\") for c in df2.columns}, inplace=True)\n",
    "\n",
    "    # ---------- formataÃ§Ã£o numÃ©rica consistente ----------\n",
    "    def _fmt(x):\n",
    "        try:\n",
    "            return float_format % float(x)\n",
    "        except Exception:\n",
    "            return x\n",
    "    df2 = df2.applymap(_fmt)\n",
    "\n",
    "    # ---------- monta LaTeX com pandas ----------\n",
    "    tbl = df2.to_latex(index=False, escape=True, longtable=longtable, bold_rows=False)\n",
    "\n",
    "    # ---------- imprime com resizebox para caber na pÃ¡gina ----------\n",
    "    # (precisa de \\usepackage{graphicx} no preÃ¢mbulo)\n",
    "    if longtable:\n",
    "        # se preferir longtable, nÃ£o hÃ¡ \"table float\"; pode combinar com landscape se quiser\n",
    "        # ainda assim encapsulamos o conteÃºdo do longtable em resizebox Ã© incomum,\n",
    "        # entÃ£o aqui imprimimos o longtable puro e confiamos na quebra automÃ¡tica.\n",
    "        print(\"\\n=== BLOCO LaTeX (COMPACTO) ===\\n\")\n",
    "        print(\n",
    "            f\"\\\\begin{longtable}{{{tbl.splitlines()[0].split('{')[-1].split('}')[0]}}}\\n\"\n",
    "            f\"\\\\caption{{{caption}}}\\\\\\\\\\n\"\n",
    "            f\"\\\\label{{{label}}}\\n\" +\n",
    "            \"\\n\".join(tbl.splitlines()[1:])  # resto do conteÃºdo gerado\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\n=== BLOCO LaTeX (COMPACTO) ===\\n\")\n",
    "        print(\n",
    "            \"\\\\begin{table}[!ht]\\n\"\n",
    "            \"\\\\centering\\n\"\n",
    "            \"\\\\resizebox{\\\\textwidth}{!}{%\\n\"\n",
    "            f\"{tbl}\\n\"\n",
    "            \"}%\\n\"\n",
    "            f\"\\\\caption{{{caption}}}\\n\"\n",
    "            f\"\\\\label{{{label}}}\\n\"\n",
    "            \"\\\\end{table}\\n\"\n",
    "        )\n",
    "\n",
    "# === chamada direta (sem salvar nada) ===\n",
    "print_latex_table_compact(\n",
    "    df_resultados,\n",
    "    caption=\"Resultados por universidade (Sigla, Campus, Estado, RMSE, sMAPE)\",\n",
    "    label=\"tab:resultados_compacto\",\n",
    "    longtable=False,  # mude para True se preferir quebra automÃ¡tica por pÃ¡ginas\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b170950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =======================================================\n",
    "# MÃ‰DIAS GERAIS DAS MÃ‰TRICAS\n",
    "# =======================================================\n",
    "def print_metric_means(df: pd.DataFrame):\n",
    "    \"\"\"Calcula e exibe as mÃ©dias de RMSE, MSE e sMAPE no console.\"\"\"\n",
    "    metricas = [\"RMSE (debias)\", \"MSE\", \"sMAPE (%)\"]\n",
    "    disponiveis = [m for m in metricas if m in df.columns]\n",
    "\n",
    "    medias = df[disponiveis].mean(numeric_only=True)\n",
    "    print(\"\\n=== MÃ‰DIAS GERAIS DAS MÃ‰TRICAS ===\")\n",
    "    for metrica, valor in medias.items():\n",
    "        print(f\"{metrica}: {valor:.3f}\")\n",
    "\n",
    "print_metric_means(df_resultados)\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# MÃ‰DIAS DAS MÃ‰TRICAS POR REGIÃƒO DO BRASIL\n",
    "# =======================================================\n",
    "def print_metric_means_by_region(df: pd.DataFrame):\n",
    "    \"\"\"Calcula e exibe as mÃ©dias de RMSE, MSE e sMAPE por regiÃ£o brasileira.\"\"\"\n",
    "\n",
    "    # Mapeamento das UFs para regiÃµes\n",
    "    regioes = {\n",
    "        \"Norte\": [\"AC\", \"AP\", \"AM\", \"PA\", \"RO\", \"RR\", \"TO\"],\n",
    "        \"Nordeste\": [\"AL\", \"BA\", \"CE\", \"MA\", \"PB\", \"PE\", \"PI\", \"RN\", \"SE\"],\n",
    "        \"Centro-Oeste\": [\"DF\", \"GO\", \"MT\", \"MS\"],\n",
    "        \"Sudeste\": [\"ES\", \"MG\", \"RJ\", \"SP\"],\n",
    "        \"Sul\": [\"PR\", \"RS\", \"SC\"]\n",
    "    }\n",
    "\n",
    "    metricas = [\"RMSE (debias)\", \"MSE\", \"sMAPE (%)\"]\n",
    "    disponiveis = [m for m in metricas if m in df.columns]\n",
    "\n",
    "    # adiciona coluna \"RegiÃ£o\"\n",
    "    df = df.copy()\n",
    "    df[\"RegiÃ£o\"] = df[\"Estado\"].map({\n",
    "        uf: regiao for regiao, ufs in regioes.items() for uf in ufs\n",
    "    })\n",
    "\n",
    "    # calcula mÃ©dias\n",
    "    medias_regiao = df.groupby(\"RegiÃ£o\")[disponiveis].mean(numeric_only=True).round(3)\n",
    "\n",
    "    print(\"\\n=== MÃ‰DIAS DAS MÃ‰TRICAS POR REGIÃƒO ===\")\n",
    "    print(medias_regiao)\n",
    "\n",
    "print_metric_means_by_region(df_resultados)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5ef77d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS POR UNIVERSIDADE â€” REDE NEURAL (TEMPERATURA) ===\n",
      "[AC] Universidade Federal do Acre (UFAC) â€“ Campus Rio Branco | MSE=1.666 | RMSE=1.291 Â°C | sMAPE=3.759 %\n",
      "[AL] Universidade Federal de Alagoas (UFAL) â€“ Campus A.C. SimÃµes (MaceiÃ³) | MSE=0.445 | RMSE=0.667 Â°C | sMAPE=1.966 %\n",
      "[AP] Universidade Federal do AmapÃ¡ (UNIFAP) â€“ Campus Marco Zero (MacapÃ¡) | MSE=0.478 | RMSE=0.691 Â°C | sMAPE=1.805 %\n",
      "[AM] Universidade Federal do Amazonas (UFAM) â€“ Campus Manaus (Setor Sul) | MSE=1.459 | RMSE=1.208 Â°C | sMAPE=3.320 %\n",
      "[BA] Universidade Federal da Bahia (UFBA) â€“ Campus Ondina (Salvador) | MSE=0.436 | RMSE=0.660 Â°C | sMAPE=1.857 %\n",
      "[CE] Universidade Federal do CearÃ¡ (UFC) â€“ Campus do Pici (Fortaleza) | MSE=0.437 | RMSE=0.661 Â°C | sMAPE=1.284 %\n",
      "[ES] Universidade Federal do EspÃ­rito Santo (UFES) â€“ Campus Goiabeiras (VitÃ³ria) | MSE=1.489 | RMSE=1.220 Â°C | sMAPE=3.730 %\n",
      "[GO] Universidade Federal de GoiÃ¡s (UFG) â€“ Campus Samambaia (GoiÃ¢nia) | MSE=1.276 | RMSE=1.130 Â°C | sMAPE=3.371 %\n",
      "[MA] Universidade Federal do MaranhÃ£o (UFMA) â€“ Cidade UniversitÃ¡ria (SÃ£o LuÃ­s) | MSE=0.288 | RMSE=0.537 Â°C | sMAPE=1.489 %\n",
      "[MT] Universidade Federal de Mato Grosso (UFMT) â€“ Campus CuiabÃ¡ | MSE=4.207 | RMSE=2.051 Â°C | sMAPE=4.993 %\n",
      "[MS] Universidade Federal de Mato Grosso do Sul (UFMS) â€“ Cidade UniversitÃ¡ria (Campo Grande) | MSE=4.318 | RMSE=2.078 Â°C | sMAPE=6.141 %\n",
      "[MG] Universidade Federal de Minas Gerais (UFMG) â€“ Campus Pampulha (Belo Horizonte) | MSE=1.539 | RMSE=1.240 Â°C | sMAPE=4.497 %\n",
      "[PA] Universidade Federal do ParÃ¡ (UFPA) â€“ Campus GuamÃ¡ (BelÃ©m) | MSE=0.549 | RMSE=0.741 Â°C | sMAPE=1.977 %\n",
      "[PB] Universidade Federal da ParaÃ­ba (UFPB) â€“ Campus I (JoÃ£o Pessoa) | MSE=0.485 | RMSE=0.697 Â°C | sMAPE=1.951 %\n",
      "[PR] Universidade Federal do ParanÃ¡ (UFPR) â€“ Centro PolitÃ©cnico (Curitiba) | MSE=4.167 | RMSE=2.041 Â°C | sMAPE=8.681 %\n",
      "[PE] Universidade Federal de Pernambuco (UFPE) â€“ Cidade UniversitÃ¡ria (Recife) | MSE=0.001 | RMSE=0.035 Â°C | sMAPE=0.139 %\n",
      "[PI] Universidade Federal do PiauÃ­ (UFPI) â€“ Campus Ministro PetrÃ´nio Portella (Teresina) | MSE=0.659 | RMSE=0.812 Â°C | sMAPE=2.099 %\n",
      "[RJ] Universidade Federal do Rio de Janeiro (UFRJ) â€“ Cidade UniversitÃ¡ria (Ilha do FundÃ£o) | MSE=2.005 | RMSE=1.416 Â°C | sMAPE=4.318 %\n",
      "[RN] Universidade Federal do Rio Grande do Norte (UFRN) â€“ Campus Central (Natal) | MSE=0.119 | RMSE=0.345 Â°C | sMAPE=0.522 %\n",
      "[RS] Universidade Federal do Rio Grande do Sul (UFRGS) â€“ Campus do Vale (Porto Alegre) | MSE=4.288 | RMSE=2.071 Â°C | sMAPE=9.398 %\n",
      "[RO] Universidade Federal de RondÃ´nia (UNIR) â€“ Campus Porto Velho | MSE=2.065 | RMSE=1.437 Â°C | sMAPE=3.780 %\n",
      "[RR] Universidade Federal de Roraima (UFRR) â€“ Campus Paricarana (Boa Vista) | MSE=1.518 | RMSE=1.232 Â°C | sMAPE=2.854 %\n",
      "[SC] Universidade Federal de Santa Catarina (UFSC) â€“ Campus Trindade (FlorianÃ³polis) | MSE=2.998 | RMSE=1.732 Â°C | sMAPE=5.830 %\n",
      "[SE] Universidade Federal de Sergipe (UFS) â€“ Campus SÃ£o CristÃ³vÃ£o | MSE=0.293 | RMSE=0.542 Â°C | sMAPE=1.409 %\n",
      "[SP] Universidade Federal do ABC (UFABC) â€“ Campus Santo AndrÃ© | MSE=3.523 | RMSE=1.877 Â°C | sMAPE=6.781 %\n",
      "[TO] Universidade Federal do Tocantins (UFT) â€“ Campus Palmas | MSE=0.687 | RMSE=0.829 Â°C | sMAPE=1.884 %\n",
      "\n",
      "=== RESULTADOS FINAIS ===\n",
      "                                         Universidade Estado    MSE  \\\n",
      "0   Universidade Federal do Acre (UFAC) â€“ Campus R...     AC  1.666   \n",
      "1   Universidade Federal de Alagoas (UFAL) â€“ Campu...     AL  0.445   \n",
      "2   Universidade Federal do AmapÃ¡ (UNIFAP) â€“ Campu...     AP  0.478   \n",
      "3   Universidade Federal do Amazonas (UFAM) â€“ Camp...     AM  1.459   \n",
      "4   Universidade Federal da Bahia (UFBA) â€“ Campus ...     BA  0.436   \n",
      "5   Universidade Federal do CearÃ¡ (UFC) â€“ Campus d...     CE  0.437   \n",
      "6   Universidade Federal do EspÃ­rito Santo (UFES) ...     ES  1.489   \n",
      "7   Universidade Federal de GoiÃ¡s (UFG) â€“ Campus S...     GO  1.276   \n",
      "8   Universidade Federal do MaranhÃ£o (UFMA) â€“ Cida...     MA  0.288   \n",
      "9   Universidade Federal de Mato Grosso (UFMT) â€“ C...     MT  4.207   \n",
      "10  Universidade Federal de Mato Grosso do Sul (UF...     MS  4.318   \n",
      "11  Universidade Federal de Minas Gerais (UFMG) â€“ ...     MG  1.539   \n",
      "12  Universidade Federal do ParÃ¡ (UFPA) â€“ Campus G...     PA  0.549   \n",
      "13  Universidade Federal da ParaÃ­ba (UFPB) â€“ Campu...     PB  0.485   \n",
      "14  Universidade Federal do ParanÃ¡ (UFPR) â€“ Centro...     PR  4.167   \n",
      "15  Universidade Federal de Pernambuco (UFPE) â€“ Ci...     PE  0.001   \n",
      "16  Universidade Federal do PiauÃ­ (UFPI) â€“ Campus ...     PI  0.659   \n",
      "17  Universidade Federal do Rio de Janeiro (UFRJ) ...     RJ  2.005   \n",
      "18  Universidade Federal do Rio Grande do Norte (U...     RN  0.119   \n",
      "19  Universidade Federal do Rio Grande do Sul (UFR...     RS  4.288   \n",
      "20  Universidade Federal de RondÃ´nia (UNIR) â€“ Camp...     RO  2.065   \n",
      "21  Universidade Federal de Roraima (UFRR) â€“ Campu...     RR  1.518   \n",
      "22  Universidade Federal de Santa Catarina (UFSC) ...     SC  2.998   \n",
      "23  Universidade Federal de Sergipe (UFS) â€“ Campus...     SE  0.293   \n",
      "24  Universidade Federal do ABC (UFABC) â€“ Campus S...     SP  3.523   \n",
      "25  Universidade Federal do Tocantins (UFT) â€“ Camp...     TO  0.687   \n",
      "\n",
      "    RMSE (debias)  sMAPE (%)  \n",
      "0           1.291      3.759  \n",
      "1           0.667      1.966  \n",
      "2           0.691      1.805  \n",
      "3           1.208      3.320  \n",
      "4           0.660      1.857  \n",
      "5           0.661      1.284  \n",
      "6           1.220      3.730  \n",
      "7           1.130      3.371  \n",
      "8           0.537      1.489  \n",
      "9           2.051      4.993  \n",
      "10          2.078      6.141  \n",
      "11          1.240      4.497  \n",
      "12          0.741      1.977  \n",
      "13          0.697      1.951  \n",
      "14          2.041      8.681  \n",
      "15          0.035      0.139  \n",
      "16          0.812      2.099  \n",
      "17          1.416      4.318  \n",
      "18          0.345      0.522  \n",
      "19          2.071      9.398  \n",
      "20          1.437      3.780  \n",
      "21          1.232      2.854  \n",
      "22          1.732      5.830  \n",
      "23          0.542      1.409  \n",
      "24          1.877      6.781  \n",
      "25          0.829      1.884  \n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# REDE NEURAL (MLP) PARA TODAS AS UNIVERSIDADES (TEMPERATURA)\n",
    "# =======================================================\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# -----------------------------\n",
    "# CONFIGURAÃ‡Ã•ES\n",
    "# -----------------------------\n",
    "STATIONS_CSV = \"../data/all_stations.csv\"\n",
    "CLEANED_BASE = \"../data/cleaned_data\"\n",
    "UNI_CSV = \"./universidades_federais_coords_26_estados.csv\"\n",
    "YEARS = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "RADIUS_KM = 35.0\n",
    "RESAMPLE_RULE = \"D\"    # mÃ©dia diÃ¡ria\n",
    "SPLIT_TRAIN = 0.80     # 80/20 treino/teste\n",
    "FORECAST_PARAMETER = \"TEMPERATURA DO AR - BULBO SECO, HORARIA (Â°C)\"\n",
    "\n",
    "N_PAST = 7\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "LR = 1e-3\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# -----------------------------\n",
    "# FUNÃ‡Ã•ES AUXILIARES\n",
    "# -----------------------------\n",
    "def smape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float).ravel()\n",
    "    y_pred = np.asarray(y_pred, dtype=float).ravel()\n",
    "    denom = (np.abs(y_pred) + np.abs(y_true))\n",
    "    denom[denom == 0] = 1e-12\n",
    "    return 100 * np.mean(2 * np.abs(y_pred - y_true) / denom)\n",
    "\n",
    "def safe_align_and_mask(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true, dtype=float).ravel()\n",
    "    y_pred = np.asarray(y_pred, dtype=float).ravel()\n",
    "    n = min(len(y_true), len(y_pred))\n",
    "    y_true = y_true[:n]\n",
    "    y_pred = y_pred[:n]\n",
    "    mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "    return y_true[mask], y_pred[mask]\n",
    "\n",
    "def _calc_dist_from_coord(row, given_point_coord):\n",
    "    station_coord = (row[\"LATITUDE:\"], row[\"LONGITUDE:\"])\n",
    "    return geodesic(station_coord, given_point_coord).kilometers\n",
    "\n",
    "def _load_all_stations():\n",
    "    df = pd.read_csv(STATIONS_CSV, decimal=\",\", sep=\";\")\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def _load_weather_for_station_filename(filename_2019: str):\n",
    "    dfs = []\n",
    "    for year in YEARS:\n",
    "        year_dir = f\"{year}_cleaned\"\n",
    "        target = filename_2019.replace(\"2019\", str(year))\n",
    "        path = os.path.join(CLEANED_BASE, year_dir, target)\n",
    "        if os.path.exists(path):\n",
    "            try:\n",
    "                dfw = pd.read_csv(path, decimal=\".\", sep=\";\")\n",
    "                if 'RADIACAO GLOBAL (Kj/mÂ²)' in dfw.columns:\n",
    "                    dfw.rename(columns={'RADIACAO GLOBAL (Kj/mÂ²)': 'RADIACAO GLOBAL (KJ/mÂ²)'}, inplace=True)\n",
    "                dfs.append(dfw)\n",
    "            except Exception as e:\n",
    "                print(f\"[WARN] Falha ao ler {path}: {e}\")\n",
    "    if not dfs:\n",
    "        return None\n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "def _build_daily_panel_from_stations(df_nearest_stations: pd.DataFrame):\n",
    "    collected = []\n",
    "    for filename in df_nearest_stations[\"Arquivo\"]:\n",
    "        dfw = _load_weather_for_station_filename(filename)\n",
    "        if dfw is not None:\n",
    "            collected.append(dfw)\n",
    "    if not collected:\n",
    "        return None\n",
    "\n",
    "    df = pd.concat(collected, ignore_index=True)\n",
    "    if \"Hora UTC\" in df.columns:\n",
    "        df = df.drop(columns=[\"Hora UTC\"])\n",
    "    df[\"Data\"] = pd.to_datetime(df[\"Data\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Data\"]).sort_values(\"Data\").set_index(\"Data\")\n",
    "    daily = df.resample(RESAMPLE_RULE).mean(numeric_only=True)\n",
    "    daily = daily.ffill().bfill()\n",
    "    return daily if FORECAST_PARAMETER in daily.columns else None\n",
    "\n",
    "def _series_for_coord(coord, df_all_stations):\n",
    "    df = df_all_stations.copy()\n",
    "    df[\"Distancia\"] = df.apply(lambda r: _calc_dist_from_coord(r, coord), axis=1)\n",
    "    df_nearest = df[df[\"Distancia\"] < RADIUS_KM]\n",
    "    if df_nearest.empty:\n",
    "        df_nearest = df.sort_values(\"Distancia\").head(1)\n",
    "    return _build_daily_panel_from_stations(df_nearest)\n",
    "\n",
    "def _make_windows(series_vals: np.ndarray, n_past: int):\n",
    "    X, y = [], []\n",
    "    for i in range(len(series_vals) - n_past):\n",
    "        X.append(series_vals[i:i+n_past])\n",
    "        y.append(series_vals[i+n_past])\n",
    "    return np.array(X, dtype=float), np.array(y, dtype=float)\n",
    "\n",
    "# -----------------------------\n",
    "# REDE NEURAL CLIMÃTICA\n",
    "# -----------------------------\n",
    "class RedeClimatica(nn.Module):\n",
    "    def __init__(self, n_past):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(n_past, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        return self.fc3(x)\n",
    "\n",
    "def fit_predict_mlp(train_windows, train_targets, test_windows):\n",
    "    X_train_t = torch.tensor(train_windows, dtype=torch.float32)\n",
    "    y_train_t = torch.tensor(train_targets, dtype=torch.float32).unsqueeze(1)\n",
    "    X_test_t  = torch.tensor(test_windows, dtype=torch.float32)\n",
    "\n",
    "    train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = RedeClimatica(train_windows.shape[1])\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    model.train()\n",
    "    for _ in range(EPOCHS):\n",
    "        for Xb, yb in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            out = model(Xb)\n",
    "            loss = criterion(out, yb)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_t).squeeze().numpy()\n",
    "    return y_pred\n",
    "\n",
    "# -----------------------------\n",
    "# EXECUÃ‡ÃƒO PRINCIPAL\n",
    "# -----------------------------\n",
    "df_uni = pd.read_csv(UNI_CSV)\n",
    "df_uni.columns = [c.strip() for c in df_uni.columns]\n",
    "df_all_st = _load_all_stations()\n",
    "\n",
    "print(\"\\n=== RESULTADOS POR UNIVERSIDADE â€” REDE NEURAL (TEMPERATURA) ===\")\n",
    "rows_nn = []\n",
    "\n",
    "for i, row in df_uni.iterrows():\n",
    "    uni, uf = row[\"Universidade\"], row[\"Estado\"]\n",
    "    coord = (row[\"Latitude\"], row[\"Longitude\"])\n",
    "\n",
    "    daily = _series_for_coord(coord, df_all_st)\n",
    "    if daily is None:\n",
    "        print(f\"[{uf}] {uni}: Falhou â€” sem dados.\")\n",
    "        continue\n",
    "\n",
    "    y_daily = daily[FORECAST_PARAMETER].astype(float).ffill().bfill().dropna()\n",
    "    if len(y_daily) < (365 // 2):\n",
    "        print(f\"[{uf}] {uni}: SÃ©rie curta ({len(y_daily)} dias).\")\n",
    "        continue\n",
    "\n",
    "    split_idx = int(len(y_daily) * SPLIT_TRAIN)\n",
    "    scaler = MinMaxScaler()\n",
    "    y_scaled = scaler.fit_transform(y_daily.to_numpy().reshape(-1, 1)).flatten()\n",
    "\n",
    "    X_all, y_all = _make_windows(y_scaled, N_PAST)\n",
    "    if len(y_all) < 10:\n",
    "        print(f\"[{uf}] {uni}: Poucos dados.\")\n",
    "        continue\n",
    "\n",
    "    split_win = max(1, split_idx - N_PAST)\n",
    "    X_train, y_train = X_all[:split_win], y_all[:split_win]\n",
    "    X_test, y_test = X_all[split_win:], y_all[split_win:]\n",
    "\n",
    "    y_pred = fit_predict_mlp(X_train, y_train, X_test)\n",
    "\n",
    "    y_pred_inv = scaler.inverse_transform(y_pred.reshape(-1, 1)).flatten()\n",
    "    y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    y_true_clean, y_pred_clean = safe_align_and_mask(y_test_inv, y_pred_inv)\n",
    "    if y_true_clean.size == 0:\n",
    "        print(f\"[{uf}] {uni}: sem pontos vÃ¡lidos.\")\n",
    "        continue\n",
    "\n",
    "    mse = mean_squared_error(y_true_clean, y_pred_clean)\n",
    "    rmse = float(mse ** 0.5)\n",
    "    smape_val = float(smape(y_true_clean, y_pred_clean))\n",
    "\n",
    "    print(f\"[{uf}] {uni} | MSE={mse:.3f} | RMSE={rmse:.3f} Â°C | sMAPE={smape_val:.3f} %\")\n",
    "\n",
    "    rows_nn.append({\n",
    "        \"Universidade\": uni,\n",
    "        \"Estado\": uf,\n",
    "        \"MSE\": round(float(mse), 3),\n",
    "        \"RMSE (debias)\": round(rmse, 3),\n",
    "        \"sMAPE (%)\": round(smape_val, 3)\n",
    "    })\n",
    "\n",
    "df_resultados_mlp = pd.DataFrame(rows_nn)\n",
    "print(\"\\n=== RESULTADOS FINAIS ===\")\n",
    "print(df_resultados_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f6bd8c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MÃ‰DIAS GERAIS DAS MÃ‰TRICAS ===\n",
      "RMSE (debias): 1.125\n",
      "MSE: 1.592\n",
      "sMAPE (%): 3.455\n",
      "\n",
      "=== MÃ‰DIAS DAS MÃ‰TRICAS POR REGIÃƒO ===\n",
      "              RMSE (debias)    MSE  sMAPE (%)\n",
      "RegiÃ£o                                       \n",
      "Centro-Oeste          1.753  3.267      4.835\n",
      "Nordeste              0.551  0.351      1.413\n",
      "Norte                 1.061  1.203      2.768\n",
      "Sudeste               1.438  2.139      4.832\n",
      "Sul                   1.948  3.818      7.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69084/868366476.py:66: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df2 = df2.applymap(_fmt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BLOCO LaTeX (COMPACTO) ===\n",
      "\n",
      "\\begin{table}[!ht]\n",
      "\\centering\n",
      "\\resizebox{\\textwidth}{!}{%\n",
      "\\begin{tabular}{lllll}\n",
      "\\toprule\n",
      "Sigla & Campus & Estado & RMSE (debias) & sMAPE (\\textbackslash \\%) \\\\\n",
      "\\midrule\n",
      "UFAC & Rio Branco & AC & 1.291 & 3.759 \\\\\n",
      "UFAL & A.C. SimÃµes (MaceiÃ³ & AL & 0.667 & 1.966 \\\\\n",
      "UNIFAP & Marco Zero (MacapÃ¡ & AP & 0.691 & 1.805 \\\\\n",
      "UFAM & Manaus (Setor Sul & AM & 1.208 & 3.320 \\\\\n",
      "UFBA & Ondina (Salvador & BA & 0.660 & 1.857 \\\\\n",
      "UFC & do Pici (Fortaleza & CE & 0.661 & 1.284 \\\\\n",
      "UFES & Goiabeiras (VitÃ³ria & ES & 1.220 & 3.730 \\\\\n",
      "UFG & Samambaia (GoiÃ¢nia & GO & 1.130 & 3.371 \\\\\n",
      "UFMA & Sede & MA & 0.537 & 1.489 \\\\\n",
      "UFMT & CuiabÃ¡ & MT & 2.051 & 4.993 \\\\\n",
      "UFMS & Sede & MS & 2.078 & 6.141 \\\\\n",
      "UFMG & Pampulha (Belo Horizonte & MG & 1.240 & 4.497 \\\\\n",
      "UFPA & GuamÃ¡ (BelÃ©m & PA & 0.741 & 1.977 \\\\\n",
      "UFPB & I (JoÃ£o Pessoa & PB & 0.697 & 1.951 \\\\\n",
      "UFPR & Sede & PR & 2.041 & 8.681 \\\\\n",
      "UFPE & Sede & PE & 0.035 & 0.139 \\\\\n",
      "UFPI & Ministro PetrÃ´nio Portella (Teresina & PI & 0.812 & 2.099 \\\\\n",
      "UFRJ & Sede & RJ & 1.416 & 4.318 \\\\\n",
      "UFRN & Central (Natal & RN & 0.345 & 0.522 \\\\\n",
      "UFRGS & do Vale (Porto Alegre & RS & 2.071 & 9.398 \\\\\n",
      "UNIR & Porto Velho & RO & 1.437 & 3.780 \\\\\n",
      "UFRR & Paricarana (Boa Vista & RR & 1.232 & 2.854 \\\\\n",
      "UFSC & Trindade (FlorianÃ³polis & SC & 1.732 & 5.830 \\\\\n",
      "UFS & SÃ£o CristÃ³vÃ£o & SE & 0.542 & 1.409 \\\\\n",
      "ABC & Santo AndrÃ© & SP & 1.877 & 6.781 \\\\\n",
      "UFT & Palmas & TO & 0.829 & 1.884 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n",
      "}%\n",
      "\\caption{Resultados por universidade (Sigla, Campus, Estado, RMSE, sMAPE)}\n",
      "\\label{tab:resultados_compacto}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =======================================================\n",
    "# MÃ‰DIAS GERAIS DAS MÃ‰TRICAS\n",
    "# =======================================================\n",
    "print_metric_means(df_resultados_mlp)\n",
    "\n",
    "\n",
    "# =======================================================\n",
    "# MÃ‰DIAS DAS MÃ‰TRICAS POR REGIÃƒO DO BRASIL\n",
    "# =======================================================\n",
    "print_metric_means_by_region(df_resultados_mlp)\n",
    "\n",
    "print_latex_table_compact(\n",
    "    df_resultados_mlp,\n",
    "    caption=\"Resultados por universidade (Sigla, Campus, Estado, RMSE, sMAPE)\",\n",
    "    label=\"tab:resultados_compacto\",\n",
    "    longtable=False,  # mude para True se preferir quebra automÃ¡tica por pÃ¡ginas\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
